{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 2_webmaps_and_distributions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Francoz-Charlotte/Spatial_teaching_CFediting/blob/master/2_webmaps_and_distributions_CFediting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEKQmmmkiIio",
        "colab_type": "text"
      },
      "source": [
        "## Getting started ### \n",
        "\n",
        "<font color='orangered'> ~ déjà vu ~</font> if you haven't already done so: You need your own copy of this notebook. Go to \"File\" and 'save a copy in github' (give access if needed.... put it into the repository you made for this course). Now you have your own copy of the notebook. Click 'open in colab' to get started working on the practical exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1zyXWFvOql5",
        "colab_type": "text"
      },
      "source": [
        "# Interactive maps and looking more at distributions\n",
        "\n",
        "Last week, we focused on making mostly static maps, that is maps where you mostly just expect your user to look at the product you've prepared. Around a research question about iron age sites distribution in Central Italy, we focussed the practical on the purpose of the output (i.e. the map) through:\n",
        "  * data exploration => filtering and creating data subset\n",
        "  * visualisation => zoom level (visual balance), visual variables (symbols/forms, dimension, color) & weight\n",
        "  * organisation => difference between geospatial and attribute data (role of attribute weighting)\n",
        "\n",
        "\n",
        "This week we'll continue exploring types of output and we'll look at making maps where interactivity is part of the design. This will allow to spend some more time on that all important topic: **spatial distributions**. Central to this is our abibility to interrogate, manipulate and remodel the geospatial database and answer spatially explicit questions.  \n",
        "\n",
        "###<font color='cyan'> This practical lab will provide you ways to do so through:\n",
        "\n",
        "  * transforming database \n",
        "  * merging  database\n",
        "  * creating layers\n",
        " </font>  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVvxjDYFOkK8",
        "colab_type": "text"
      },
      "source": [
        "##Start by getting tools, always\n",
        "\n",
        "<font color='orangered'> ~ déjà vu ~</font> Last week, we worked with folium, branca and pandas libraries. \n",
        "\n",
        "<font color='magenta'> ~ new ~</font> This week, you still be working with panda and folium and you will be replacing branca library for [numpy](https://numpy.org/). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-19T05:33:33.494092Z",
          "start_time": "2018-11-19T05:33:24.204201Z"
        },
        "id": "mLiflC-JiIir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#codecell_Webmaps&Distributions_ImportUrLibraries\n",
        "\n",
        "#Like last time, get the tools we need at the start\n",
        "import pandas as pd\n",
        "import folium\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN6AB-EgPF-q",
        "colab_type": "text"
      },
      "source": [
        "## And then by getting the data\n",
        "\n",
        "This week we are working with the data from the Antikythera survey project.\n",
        "\n",
        "\n",
        "It's citation is: Bevan, A. and Conolly, J. 2012. Intensive Survey Data from Antikythera, Greece. **Journal of Open Archaeology Data** 1(1), DOI: http://dx.doi.org/10.5334/4f3bcb3f7f21d.\n",
        "\n",
        "This data has been made available at the Archaeological Data Service (ADS) archive at https://archaeologydataservice.ac.uk/archives/view/antikythera_ahrc_2012/ and completely open for re-use. You can [see](https://archaeologydataservice.ac.uk/archives/view/antikythera_ahrc_2012/stats.cfm) how many times their database has been viewed and downloaded. \n",
        "\n",
        "\n",
        "### Open Data\n",
        "\n",
        "Last week we mentioned open source software. Open data operates under the same broad ethos, and follows many of the same principles. Sharing, reuse, and attribution are key. If you continue to reuse the Antikythera data, be sure to continue to link back to and cite the source.\n",
        "\n",
        "Perhaps the most relevant example in the UK is **OS (Ordnance survey) OpenData** which was made freely available for the first time in 2010. Last review ([2018](https://www.ordnancesurvey.co.uk/business-government/tools-support/open-data-support)) counted 1.9 million open data downloads, the equivalent of 150 people download OS OpenData every day!\n",
        "\n",
        "2015 has seen Environmental Agency made **lidar (light detection and ranging)** data available to the public, for free, as open data. Within the first year of release 500,000 lidar downloads were made equating to nearly 13 million km2 of data! \n",
        "\n",
        "\n",
        "### Working with other people's data: the case of Antikythera \n",
        "\n",
        "Have a quick look around the dataset as it's described on the ADS site. You'll notice that they've split up their dataset in ways that made sense to them at the time. Specifically they've divided up the artefact data into three discrete elements: 'pottery', 'lithics' and 'other' into separate files (very much like we did last week by filtering and creating a subset). This is a pretty normal archaeological data thing to do. \n",
        "\n",
        "Here's the trick, we want to focus on both **ceramics and small finds** and to look at these datasets together. This means you'll have to grab both of them and <font color='magenta'> **combine** </font>them. You are organising the attribute data in order to reuse it for something new. This is thinking of a <font color='magenta'> **relational database model**</font>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up4gTxO6Ukzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#codecell_Webmaps&Distributions_OrganisingUrdata\n",
        "\n",
        "#Like last time, get the data we'll need at the start. I've been nice again and converted their coordinates to latitude and longitude for you. \n",
        "#You'll learn to do this yourself later in the course.\n",
        "\n",
        "# we label the first dataset 'pottery'\n",
        "pottery = pd.read_csv('https://raw.githubusercontent.com/ropitz/spatialarchaeology/master/data/antikythera_survey_pottery.csv')\n",
        "\n",
        "# we label the second dataset 'small finds'\n",
        "small_finds = pd.read_csv('https://raw.githubusercontent.com/ropitz/spatialarchaeology/master/data/antikythera_survey_small_finds.csv')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3MV8nj-VKzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#codecell_Webmaps&Distributions_CheckingZeData\n",
        "\n",
        "#let's check the individual pottery file.  \n",
        "pottery.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRR2Nyugbnh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#codecell_Webmaps&Distributions_CheckingZeData\n",
        "\n",
        "#let's check the individual pottery file to see \n",
        "small_finds.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrtIpk4DS-DK",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "###Learning a new language – decomposing the code\n",
        "<font color='orangered'> ~ déjà vu ~</font> \n",
        "* **=**    allows you to provide a new name, often more convenient than the link pathname\n",
        "* **pd.read_csv** allows you to open a CSV format file\n",
        "\n",
        "* **.head() function** take a peek at the first part of the dataset \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Here have a look at these 2 datasets and how they are structured. Also, the coordinates have been transformed for you from cartesian co-ordinates (grid system - shown in column *'Xsugg' &\t'Ysugg'*) back to latitude/longitude (geodetic system - shown in column *'DDlat' &\t'DDlong'*). Below is a very crude diagram demonstrating this transformation. \n",
        "\n",
        "<img src=\"https://github.com/Francoz-Charlotte/Spatial_teaching_CFediting/blob/master/x&y_webmaps&distribution.png?raw=1\" width=\"300\"/>\n",
        "</div>\n",
        "\n",
        "Whilst the conversion from geodetic to cartesian is fairly straightforward, converting cartesian to geodetic is a complex problem (& if you are interested on how this is done mathematically have a look at [this](https://www.movable-type.co.uk/scripts/latlong-os-gridref.html)).\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIQ_n9BCY1cu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#codecell_Webmaps&Distributions_Concatenation\n",
        "\n",
        "# then we combine the two datasets together to make a big dataset we call 'survey data'\n",
        "survey_data = pd.concat([pottery,small_finds], sort=False, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjpgcdojY5NJ",
        "colab_type": "text"
      },
      "source": [
        "##Learning a new language – decomposing the code\n",
        "<font color='magenta'> ~ new ~  </font> the pd.concat function\n",
        "\n",
        "![](https://github.com/Francoz-Charlotte/Spatial_teaching_CFediting/blob/master/?raw=1#codecell_Webmaps&Distributions_Concatenation.jpg)\n",
        "\n",
        "* **Reminder**: an array is a group of elements/objects/items organised as a set where columns (of equal size) are multiplied by rows (of equal size). The advantage of using arrays is that  all elements can be accessed at any time randomly. \n",
        "\n",
        "Last week, you had done something similar to call all items from the range [i] ( <font color='orangered'>in #codecell_makeabasicmap_BringingUrData2theMap </font>). This week, you are linking together 2 arrays. Pandas library provides various ways to combine together Series or DataFrame such as merge, join and concatenate ([see user guide](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html)). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_62uXk_TQwVY",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Let's make sure nothing went wrong..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv4XxSSQU2YT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#codecell_Webmaps&Distributions_CheckingZeData\n",
        "\n",
        "#check things loaded in and combined OK\n",
        "survey_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZqevW03Q4ig",
        "colab_type": "text"
      },
      "source": [
        "# Now ask a question\n",
        "\n",
        "Like we said last week, we are using maps and spatial analysis to pose, explore and respond to spatial questions. \n",
        "\n",
        "My question is a bit like last week's question. I want to know about how many sites are in each period, so I can try and understand changing patterns over time. \n",
        "\n",
        "However, you may have noticed when you read in the data that it's structure is a bit different from last week's data. Instead of each site belonging to one period, it's assinged with varying probability to several different periods. \n",
        "\n",
        "This is a totally legit archaeological thing to do. Many sites have activity from multiple periods, and depending on the available evidence, you might be more or less confident about the presence or absence of activity in a specific period. \n",
        "\n",
        "### So what do we do now?\n",
        "\n",
        "We might start simply by assigning each site primarily to its 'most likely period'. \n",
        "\n",
        "This takes a few steps....\n",
        "\n",
        "###<font color='green'> - this takes few steps because you have to re-think the dataset to answer your question- </font>  \n",
        "\n",
        "###<font color='green'> you have to re-think the dataset to answer our question:\n",
        "\n",
        "  * this is data cleaning and is the most consumming part of anay analysis - and not only in archaeology but fo all Sciences analyses in general-.\n",
        "</font>  \n",
        "\n",
        "\n",
        "\n",
        "### step 1 - prepare the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbjLzluu1kx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first we create a subset of our data that only contains the columns with information about time\n",
        "# this is in part because we want to do some operations where everything has to be a number, and some of the other fields contain text\n",
        "# it's also just to make things simpler when we look at them\n",
        "\n",
        "survey_data_time = survey_data[['MNLN', 'FNEB1',\t'EB2',\t'LPrePal', 'FPal', 'SPal', 'TPal', 'PPalPG', 'Geom', 'Arch', 'Class', 'Hell', 'ERom', 'MRom', 'LRom', 'EByz', 'MByz', 'EVen', 'MVen', 'LVen', 'Recent', 'Other']]\n",
        "survey_data_time.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P23K0yo2y5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if you were to look through this data, you'd see some fields with null values\n",
        "# null values can break number-based operations\n",
        "# let's get rid of null values and make sure everything is a number\n",
        "survey_data_time.astype('float64').fillna(0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym3UIQjPZ3Y5",
        "colab_type": "text"
      },
      "source": [
        "### step 2 - transform the data\n",
        "\n",
        "Data transformation is an important thing to learn to do.\n",
        "\n",
        "###<font color='green'> - data transdormation is a wrong terminology here! transformati on is specific mathematical operation, here you are not transforming projections, matrices or else!- </font> \n",
        "\n",
        "Right now we have a bunch of columns with information about time. \n",
        "\n",
        "What we want is one single column that contains the most likely period - which is represented in each row by the column with the greatest value.\n",
        "\n",
        "*think about that for a moment*\n",
        "\n",
        "Right now the 'most likely period' is represented by a number in each row, but that's not the piece of information we want in our new column - we want the name of the column that contains that number.\n",
        "\n",
        "**Data Transformation describes what we are doing here - reorganising the data in our table**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VTV0zNi8TBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#here we take the columns from all the different periods, get the one with the maximum value, and write that column's name to our new 'colmax' field\n",
        "def returncolname(row, colnames):\n",
        "    return colnames[np.argmax(row.values)]\n",
        "\n",
        "survey_data_time['colmax'] = survey_data_time.apply(lambda x: returncolname(x, survey_data_time.columns), axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcza17og5zeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#we can check it has all gone well\n",
        "survey_data_time.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5iNwhgraxn9",
        "colab_type": "text"
      },
      "source": [
        "## Merging tables\n",
        "\n",
        "OK now we have a single column with the information we need - the most likely date. To create this column, we broke off some of our data (the columns with numbers) from the rest of the data (important descriptive text). We might well want to stick these two datasets back together before proceeding. \n",
        "\n",
        "**splitting and merging tables is another basic skill when working with data**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LxENtT79Rvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#now we can also add our new column back to our original data table by doing a 'merge'\n",
        "#create a new table 'survey_data_maxtime' by merging our original 'survey_data' with ONLY the 'colmax' column from our new table\n",
        "survey_data_maxtime = pd.merge(survey_data, survey_data_time['colmax'], how='inner', left_index=True, right_index=True)\n",
        "survey_data_maxtime.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tbZd-bqVx7p",
        "colab_type": "text"
      },
      "source": [
        "## The curse of abbreviations\n",
        "\n",
        "Have a look at the resulting table. What do all those column names mean? Right now you are probably justifiably confused. We'll be talking more about the mess that is 'other people's data' next week. For now, have a look at the documentation for these datasets at: https://archaeologydataservice.ac.uk/catalogue/adsdata/arch-1115-2/dissemination/csv/pottery/documentation/pottery.txt\n",
        "\n",
        "You'll see they explain that many of those weird abbreviations are periods and that the number in each one represents the chance that a given find belongs to that period. Sometimes I wish people wouldn't use abbreviations like this, but they've defined them in their metadata file, so we can't compain too much."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZeKlPYrbzT3",
        "colab_type": "text"
      },
      "source": [
        "## Finally, we make maps!\n",
        "\n",
        "\n",
        "We're going to look at a couple different ways of making maps, because there are lots of tools we can use to do this.\n",
        "\n",
        "### Maps for visualization and interpretation\n",
        "\n",
        "Broadly speaking, there are two ways to approach interpreting spatial patterns. There's visualisation and interpretation, where you might visually compare distributions or densities or locations of two or more datasets by plotting them on a map and intepreting what you see. Then there's statistical analysis. \n",
        "\n",
        "We'll start with the tools to do the first one, and introduce statistical analysis later in the course. \n",
        "\n",
        "We'll also discuss the value of each approach, and when to apply it.\n",
        "\n",
        "### As always, start with a question\n",
        "\n",
        "As we said at the beginning of today, we're interested in change over time.\n",
        "\n",
        "**Analysis Question:**<br>\n",
        "How does the distrubution of finds change between different periods?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYZwq0DesMEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we're going to get geopandas, another tool for making maps\n",
        "!pip install geopandas\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RdAEMkRsl11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get some more tools for making maps (and other things)\n",
        "\n",
        "%matplotlib inline\n",
        "import geopandas as gpd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6MYggBtwUnd",
        "colab_type": "text"
      },
      "source": [
        "## Geopandas\n",
        "\n",
        "We're going to introduce a new mapping tool - geopandas. \n",
        "\n",
        "It can do many of the same things as folium, which we were using before.\n",
        "\n",
        "It's particularly useful for showing categorical data. \n",
        "###<font color='green'> - simple image to present cat vs numerical data ie rankng and random and explain the importance for distribution?- </font> \n",
        "\n",
        "What's categorical data? It's anything where you have a category label, like an archaeological period. \n",
        "\n",
        "We could start tryping to see and understand the distributions of our sites by periods simply by mapping the period labels with different colors.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpBpnIxBrWq6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# take our big dataset from above and turn it from a 'dataframe' which is the data that folium uses to make maps into a 'geodataframe' which is the data geopandas uses to make maps\n",
        "\n",
        "gdf_survey = gpd.GeoDataFrame(\n",
        "    survey_data_maxtime, geometry=gpd.points_from_xy(survey_data_maxtime.DDLon, survey_data_maxtime.DDLat))\n",
        "print(gdf_survey.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6Hmn-KFvz8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot your data colouring the points by the period to which they belong\n",
        "gdf_survey.plot(column='colmax', categorical=True, legend=True, figsize=(15,15))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0k9G6d0yVPO",
        "colab_type": "text"
      },
      "source": [
        "### Assess the resulting map\n",
        "\n",
        "Is it useful? Why or why not?\n",
        "\n",
        "Can you see the distribution of sites from individual periods easily?\n",
        "\n",
        "Can you easily discern change over time?\n",
        "\n",
        "I'm not overly convinced by the result here.\n",
        "\n",
        "What other approach might we take?\n",
        "\n",
        "\n",
        "Let's try something else\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZFoGw070Yq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Maybe it would be better to only look at two or three periods at a time\n",
        "\n",
        "#let's select a subset of our periods to see change from the early bronze age to hellenistic to late roman\n",
        "\n",
        "types = ['EB2','Hell','LRom']\n",
        "classic = gdf_survey.loc[gdf_survey['colmax'].isin(types)]\n",
        "classic.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROpEOeRw1TZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot your data colouring the points by the period to which they belong\n",
        "classic.plot(column='colmax', categorical=True, legend=True, figsize=(15,15))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQu68G8o1bDi",
        "colab_type": "text"
      },
      "source": [
        "## Thinking about data visualization and map design\n",
        "\n",
        "That's a bit better perhaps. The map is less crowded.\n",
        "\n",
        "Recall our discussions about how to design a map well. Clearly too much data introduces design problems.\n",
        "\n",
        "Well, now we can see the distributions a bit, and maybe say something about change over time, but there are still a lot of dots, and it's pretty clear dots from some periods are hidden under dots from other periods and we have no way to separate them. \n",
        "\n",
        "**what we need here is layers, so we can group our data and work with it interactively**\n",
        "*It would also be nice to have some context for all those dots*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8fCQvSyUrx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Like last time, we'll use folium and one of it's plugins\n",
        "from folium.plugins import HeatMapWithTime\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBXk0ENHiIjR",
        "colab_type": "text"
      },
      "source": [
        "### Map Visualizations with Folium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPAgyDlciIjR",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "To see the survey data in context and build our interactive maps, we'll start by generating the base map that will be used throughout this notebook.\n",
        "\n",
        "'Basemaps' are generic background maps, like a satellite image or an image of the street map. You know the different backgrounds you can show on google maps? Those are 'basemaps'. \n",
        "\n",
        "Have a look around the web, and you'll see that most modern online maps  use a basemap, so we're going to do so as well.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-19T05:34:04.673013Z",
          "start_time": "2018-11-19T05:34:04.670120Z"
        },
        "id": "0H-uRYF1iIjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the survey area centre, like you did last week, so you can centre the map where the data is located\n",
        "\n",
        "location_survey=survey_data_maxtime['DDLat'].mean(), survey_data_maxtime['DDLon'].mean()\n",
        "print(location_survey)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUBTM83AbAeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define a basemap we can reuse. Use the coordiantes for the centre you generated just above to centre the basemap\n",
        "#This is a variant on how we did things last time...\n",
        "\n",
        "def generateBaseMap(default_location=[35.870086207930626, 23.301798820980512], default_zoom_start=11):\n",
        "    base_map = folium.Map(location=default_location, control_scale=True, zoom_start=default_zoom_start)\n",
        "    return base_map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-qIFOBUiIjU",
        "colab_type": "text"
      },
      "source": [
        "### Review - basic map controls\n",
        "\n",
        "Arguments:<br><br>\n",
        "location: Define the default location to zoom at when rendering the map<br>\n",
        "zoom_start: The zoom level that the map will default to when rendering the map<br>\n",
        "control_scale: Shows the map scale for a given zoom level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8ffsWcqSyKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-19T05:34:04.687135Z",
          "start_time": "2018-11-19T05:34:04.674745Z"
        },
        "id": "ZhOzNzEEiIjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check the basemap is working\n",
        "base_map = generateBaseMap()\n",
        "base_map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JcHrzMTZxk0b"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-19T06:05:45.764352Z",
          "start_time": "2018-11-19T06:05:45.761769Z"
        },
        "id": "--pBpUiviIjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#lets get the heatmap tool, like last time, let's also get a measure control so we can measure distance\n",
        "from folium import plugins\n",
        "from folium.plugins import HeatMap\n",
        "from folium.plugins import MeasureControl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-4G4lb9iIje",
        "colab_type": "text"
      },
      "source": [
        "Let's start by comparing MRom to LRom, that is middle roman to late roman sites by putting their data in separate layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-19T05:34:05.037298Z",
          "start_time": "2018-11-19T05:34:04.818915Z"
        },
        "id": "2p4cDhYeiIjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make a layer for when each period is more than 50% likely, so you have all the sites that are probably in that period\n",
        "survey_data_MRom = survey_data_maxtime.loc[(survey_data_maxtime['MRom'] > 50)]\n",
        "survey_data_ERom = survey_data_maxtime.loc[(survey_data_maxtime['ERom'] > 50)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Da1dgQn7fsXx",
        "colab_type": "text"
      },
      "source": [
        "### The concept of layers\n",
        "\n",
        "We've introduced a new concept here. Maps have 'layers'. Each layer contains information and can be turned on and off. Think of this like a stack of transparent paper. Each sheet of paper is a layer, and can be added to or taken away from the stack. Their order can also be changed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-19T10:09:37.970112Z",
          "start_time": "2018-11-19T10:09:34.940649Z"
        },
        "id": "DxWjo2YUiIjo",
        "colab_type": "code",
        "outputId": "6c1d8680-84f7-452d-8edd-efbbfc9fa04d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# like last time, make heatmaps, but one for each period,  put them in different layers.\n",
        "base_map = generateBaseMap()\n",
        "mrom = HeatMap(data=survey_data_MRom[['DDLat', 'DDLon', 'MRom']].groupby(['DDLat', 'DDLon']).sum().reset_index().values.tolist(), radius=8, max_zoom=13).add_to(base_map)\n",
        "erom = HeatMap(data=survey_data_ERom[['DDLat', 'DDLon', 'ERom']].groupby(['DDLat', 'DDLon']).sum().reset_index().values.tolist(), radius=8, max_zoom=13).add_to(base_map)\n",
        "\n",
        "#give the layers sensible names\n",
        "mrom.layer_name = 'Middle Roman Distribution'\n",
        "erom.layer_name = 'Early Roman Distribution'\n",
        "\n",
        "# add the layer control. This is the tool that lets you turn different layers in your map on and off\n",
        "folium.LayerControl().add_to(base_map)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<folium.map.LayerControl at 0x7fbf57070860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-19T10:09:48.682799Z",
          "start_time": "2018-11-19T10:09:39.486706Z"
        },
        "id": "mzgBodwBiIjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now generate your map by calling it by its name\n",
        "base_map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSCv-r8eXuXE",
        "colab_type": "text"
      },
      "source": [
        "Now try and add some more layers to the map to show other periods!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "engTEEWWe454",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make a layer for when the max period is LRom or MRom to compare these periods\n",
        "survey_data_lrommax = survey_data_maxtime.loc[(survey_data_maxtime['colmax'] =='LRom')]\n",
        "survey_data_mrommax = survey_data_maxtime.loc[(survey_data_maxtime['colmax'] =='MRom')]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_ucaKUkfW_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# like last time, make heatmaps, but one for each period,  put them in different layers\n",
        "base_map = generateBaseMap()\n",
        "\n",
        "lrommax = HeatMap(data=survey_data_lrommax[['DDLat', 'DDLon']].groupby(['DDLat', 'DDLon']).sum().reset_index().values.tolist(), radius=8, max_zoom=13).add_to(base_map)\n",
        "mrommax = HeatMap(data=survey_data_mrommax[['DDLat', 'DDLon']].groupby(['DDLat', 'DDLon']).sum().reset_index().values.tolist(), radius=8, max_zoom=13).add_to(base_map)\n",
        "\n",
        "#give the layers sensible names\n",
        "lrommax.layer_name = 'Late Roman Distribution'\n",
        "mrommax.layer_name = 'Middle Roman Distribution'\n",
        "\n",
        "# add the layer control\n",
        "folium.LayerControl().add_to(base_map)\n",
        "base_map\n",
        "\n",
        "\n",
        "# Adds a measure tool to the top right\n",
        "\n",
        "base_map.add_child(MeasureControl())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M85UnCT-lCKz",
        "colab_type": "text"
      },
      "source": [
        "# Making visual comparisons\n",
        "\n",
        "Perhaps it will be more useful to be able to view our distributions and explore them side by side, to help us compare what is happening in these two periods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NEHqdsAhYYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get another plugin for side by side maps\n",
        "from folium.plugins import DualMap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBBVGMamhNNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# declare you are making a new map \"m\"\n",
        "\n",
        "# set the location to the location of your survey, set your starting zoom\n",
        "m = plugins.DualMap(location=location_survey, tiles=None, zoom_start=13)\n",
        "\n",
        "# the dual maps plugin automatically defines two buddy maps, \"m1\" and \"m2\" which pan and zoom together\n",
        "\n",
        "# give yourself some options in life for your base layers, add them to both maps 'm1' and 'm2' by just using \"m\"\n",
        "folium.TileLayer('cartodbpositron').add_to(m)\n",
        "folium.TileLayer('openstreetmap').add_to(m)\n",
        "\n",
        "\n",
        "# like last time, make heatmaps, one for each period,  put them in different layers\n",
        "# put one layer in the left hand map 'm' and the other in the right hand map 'm2'\n",
        "\n",
        "lrommax = HeatMap(data=survey_data_lrommax[['DDLat', 'DDLon']].groupby(['DDLat', 'DDLon']).sum().reset_index().values.tolist(), radius=8, max_zoom=13).add_to(m.m1)\n",
        "mrommax = HeatMap(data=survey_data_mrommax[['DDLat', 'DDLon']].groupby(['DDLat', 'DDLon']).sum().reset_index().values.tolist(), radius=8, max_zoom=13).add_to(m.m2)\n",
        "\n",
        "#give the layers sensible names\n",
        "lrommax.layer_name = 'Late Roman Distribution'\n",
        "mrommax.layer_name = 'Middle Roman Distribution'\n",
        "\n",
        "# layer control time\n",
        "folium.LayerControl(collapsed=False).add_to(m)\n",
        "\n",
        "# Adds a measure tool to the top right\n",
        "\n",
        "m.add_child(MeasureControl())\n",
        "\n",
        "#draw your side by side maps\n",
        "\n",
        "m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYz4hI_1kImv",
        "colab_type": "text"
      },
      "source": [
        "## visualization and interpretation\n",
        "\n",
        "Thought exercise: The results of these two maps should be similar but slightly different. What is making the difference?\n",
        "\n",
        "How good are you at interpreting these distributions and comparing them visually?\n",
        "\n",
        "*This is me hinting at you that you are going to end up wanting to use statistics eventually*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWAQRddKcogi",
        "colab_type": "text"
      },
      "source": [
        " \n",
        "\n",
        "# Think about basic principles\n",
        "\n",
        "The principles of what we've done this week are the same as the principles of what we did last week. \n",
        "\n",
        "I think it's important to learn to do things more than one way, and to adapt to slightly different tools. The software and code packages used for modern spatial analysis and mapping are pretty diverse and are always developing as people improve things. It doesn't make much sense to just learn one way of making maps mechanistically. The important thing is to understand the principles of what you're doing. ###which are?####\n",
        "\n",
        "In any code package that is meant to be used for making maps, odds are good you will find a way to set the zoom level, set the centre starting location, and set the initial scale. \n",
        "\n",
        "You will be able to set up colour schemes, map attributes, and make layers. Knowing keywords and princples is the important thing. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZCz_MQuj8ZF",
        "colab_type": "text"
      },
      "source": [
        "## The End\n",
        "\n",
        "That's all for today. Be sure to save your copy of the notebook in your own repo so I can see it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nGkpE2cU9xj",
        "colab_type": "text"
      },
      "source": [
        "#LexiCode\n",
        "In last week practical you have learned new commands that you can now reuse for your own datasets:\n",
        "*\t==  , () []\n",
        "*\t.head_csv()\n",
        "*\t.read_csv()\n",
        "*\tmean()\n",
        "*\tfolium.Map\n",
        "*\trange()\n",
        "*\tlen()\n",
        "*\tiloc[]\n",
        "*\t.value_counts()\n",
        "*\tif =:\n",
        "*\telif =:\n",
        "*\telse =:\n",
        "*\tfolium.Marker()\n",
        "*\tfolium.Icon()\n",
        "*\tfolium.Circle\n",
        "*\tpopup=\n",
        "*\tradius=\n",
        "*\t.values.tolist()\n",
        "*\tplugins.HeatMap()\n",
        "\n",
        "This week:  "
      ]
    }
  ]
}