{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 4_spatial_patterns_in_excavation_data.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hiQg_M8G-BSd"
      ],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Francoz-Charlotte/Spatial_teaching_CFediting/blob/master/Copy_of_4_spatial_patterns_in_excavation_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8JEjBNu-BQW",
        "colab_type": "text"
      },
      "source": [
        "# **More about spatial patterns**\n",
        "\n",
        "\n",
        "\n",
        "Understanding the meanings behind patterns of finds recovered through excavation is a tricky problem. We hope to distinguish activity areas, places devoted to domestic and industrial use, or inhabited places that are distinct from liminal ones. We often want to discern change over time, identifying areas with finds associated with different temporal periods. \n",
        "\n",
        "To successfully unravel these patterns, we must look not only at the **distributions** of different types of finds, but how they **correlate** with one another, the character of the contexts in which they were recovered, and their own physical and social characteristics. Are they likely to be curated? Are they light and likely to be moved from one area to another by post-depositional processes? It's all a bit of a mess. \n",
        "\n",
        "Importantly, all these processes are spatial. Alignments or proximity between areas with similar (or quite different) finds is potentially meaningful. \n",
        "\n",
        "The aims of this exercise is for you to:\n",
        "* learn to work real special finds data from an excavation, in all its messiness, to look for spatial patterns and relationships. **-> improve spatial patterns recognition**\n",
        "* start thinking about quantitative and spatial approaches to finds data from excavations and how they can help us better understand the patterns we see. **-> improve spatial patterns quantification**\n",
        "\n",
        "You'll do this using data collected by the Gabii Project, a 10+ year excavation in central Italy. \n",
        "\n",
        " \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqgoptAiXijR",
        "colab_type": "text"
      },
      "source": [
        "### Let's get started...####  \n",
        "<font color='orangered'> ~ déjà vu ~</font> \n",
        "* Make your own copy of this notebook;\n",
        "* Get your tools... it is like for writing on paper, you need a pen, here you have to import your libraries...\n",
        "* Remember to hit play or type 'Ctrl'+'Enter' to run the code in any cell (grey shaded cells in the page) to make things happen!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awel6EMM-BQY",
        "colab_type": "code",
        "outputId": "179bced2-74a1-44bb-b84a-5202c1749dcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "##codecell_SpatialPatterns_ImportUrLibraries\n",
        "\n",
        "# as usual, start by getting your tools: your prerequisites.\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "# Matplotlib is your tool for drawing graphs and basic maps. You need this!\n",
        "!pip install fiona\n",
        "!pip install geopandas\n",
        "import pandas as pd\n",
        "import requests\n",
        "import fiona\n",
        "import geopandas as gpd\n",
        "import ipywidgets as widgets\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fiona\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/80/09aa6ba5e4ed3f07ddbd2204634b119cb50ae613aa182c6ee7daff3adc9b/Fiona-1.8.9.post2-cp36-cp36m-manylinux1_x86_64.whl (11.9MB)\n",
            "\u001b[K     |████████████████████████████████| 11.9MB 186kB/s \n",
            "\u001b[?25hRequirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from fiona) (7.0)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.6/dist-packages (from fiona) (19.3.0)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/be/30a58b4b0733850280d01f8bd132591b4668ed5c7046761098d665ac2174/cligj-0.5.0-py3-none-any.whl\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from fiona) (1.12.0)\n",
            "Collecting click-plugins>=1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/da/824b92d9942f4e472702488857914bdd50f73021efea15b4cad9aca8ecef/click_plugins-1.1.1-py2.py3-none-any.whl\n",
            "Installing collected packages: cligj, munch, click-plugins, fiona\n",
            "Successfully installed click-plugins-1.1.1 cligj-0.5.0 fiona-1.8.9.post2 munch-2.5.0\n",
            "Collecting geopandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/39/de0263d511d4fc35a640cf00d02e497eb60698315a22936bedbdd904d7f7/geopandas-0.6.1-py2.py3-none-any.whl (918kB)\n",
            "\u001b[K     |████████████████████████████████| 921kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: fiona in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.8.9.post2)\n",
            "Collecting pyproj\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/b1/ab67ad924770e1c1432fa0953a665b8ea193b60c7494457b69da052d6e83/pyproj-2.4.0-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 39.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.6.4.post2)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from geopandas) (0.25.2)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (19.3.0)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (1.12.0)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (2.5.0)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (0.5.0)\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (7.0)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (1.1.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (1.17.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2.6.1)\n",
            "Installing collected packages: pyproj, geopandas\n",
            "Successfully installed geopandas-0.6.1 pyproj-2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpZN9KC_ZxJ5",
        "colab_type": "text"
      },
      "source": [
        " **Learning a new language – decomposing the code** \n",
        "  <br>\n",
        "  in #codecell_SpatialPatterns_ImportUrLibraries. These are what we call **prerequisites**. You know by now that they are basic tools so you can get started.\n",
        "* *Pandas* manipulate data. \n",
        "* *Geo-pandas* manipulate geographic data. They're also black and white and like to eat bamboo...  You need these to manipulate your data!\n",
        "* *Fiona* helps with geographic data (find more about [fiona](https://pypi.org/project/Fiona/)).\n",
        "* *Requests* are for asking for things. It's good to be able to ask for things.\n",
        "* *ipywidgets* supports interactivity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDGLKQ8_iwBc",
        "colab_type": "text"
      },
      "source": [
        "### **Getting to know your Data...**####  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siGQqpwn-BQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##codecell_SpatialPatterns_ImportUrData\n",
        "\n",
        "# then get your data\n",
        "# This is where I put the data. It's in a format called geojson, used to represent spatial geometry (shapes) and attributes (text).\n",
        "url = 'http://ropitz.github.io/digitalantiquity/data/gabii_SU.geojson'\n",
        "\n",
        "# Please get me the data at that web address (url):\n",
        "# use requests.get to retrieve data from any destination\n",
        "request = requests.get(url)\n",
        "\n",
        "# I will use the letter 'b' to refer to the data, like a nickname\n",
        "#we can use requests to read the response content in bytes\n",
        "b = bytes(request.content)\n",
        "\n",
        "#So we will use fiona.BytesCollection referred by the letter 'f':\n",
        "# to read the raw data (as single-file formats or zipped shapefiles)\n",
        "# to wrap up all the data from 'b'\n",
        "# check the coordinate refereence system (crs) listed in the features\n",
        "with fiona.BytesCollection(b) as f:\n",
        "    crs = f.crs\n",
        "    #by using also GeoDataFrame.from_features you can read geospatial data that's in the url without saving that data to disk (your PC) first\n",
        "    gabii_su_poly = gpd.GeoDataFrame.from_features(f, crs=crs)\n",
        "    # and print out the first few lines of the file, so I can check everything looks ok: you know this by now...we will call .head()\n",
        "    print(gabii_su_poly.head())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bXO2Veyf4b-",
        "colab_type": "text"
      },
      "source": [
        "**Learning a new language – decomposing the code** \n",
        "  <br>\n",
        "  in #codecell_SpatialPatterns_ImportUrData:<br>\n",
        " \n",
        " <font color='magenta'>  *GeoJSON*  </font>  is used to store the excavation data. GeoJSON format allows to encode a variety of geographic data structures which contains features with spatial attributes (e.g. points, line strings, polygons, multiparts geometries) and non-spatial attributes (text). This is a really useful format to use when creating a GIS. <br>\n",
        "  <font color='magenta'>  *bytes()*  </font>  method returns bytes object which is an immmutable (cannot be modified) sequence of integers. We tend to use this to compress data, save or send it. <br>\n",
        "  <font color='magenta'>  *requests.get*  </font> is used to retrieve data from any destination & <font color='magenta'>  *requests.content*  </font>  to read all content which is in bytes (for non-text requests using the .content property).<br>\n",
        "<font color='magenta'>  *BytesCollection()*  </font>  takes a buffer of bytes and maps to a virtual file that can then be opened by fiona. By using  both fiona.BytesCollection and GeoDataFrame.from_features you can:\n",
        "* to read the raw data (as single-file formats or zipped shapefiles)\n",
        "* to wrap up all the data from 'b'\n",
        "* check the coordinate refereence system (crs) listed in the features\n",
        "\n",
        "\n",
        " **Open source**\n",
        "\n",
        "For the past month, we have entirely benefitted from open-source software, data, tools, code, design documents, or content. It is only natural to open, share and use the results of 10 years excavation..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aXd2B1bre1_",
        "colab_type": "text"
      },
      "source": [
        "### **Visual assessment of your Data...**####  \n",
        "   So you know what's in this dataset... Maybe you want to see it before you can question it? ... Start by visualising the spatial data for all the contexts (stratigraphic units) from the excavation we'll be exploring.\n",
        "\n",
        "So far you have dealt with survey data where all data has been logged with coordinates (x, y and sometimes z for the elevation height). However, it is not always possible, or even meaningful, to record the coordinates of all artefacts retrieved during an excavation, especially if it lasts over several years. It is then more appropriate to use stratigraphical units (SU). The spatial analysis of these finds is more subtle as they don't have a spatial location per se. We need to think carefully about organising and presenting them. AND colour can be a great help for this!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVIYnLr0-BQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now we have polygons, the shapes of our contexts. Let's visualise the data to double check that all is well\n",
        "\n",
        "gabii_map1 = gabii_su_poly.plot(column='DESCRIPTIO', cmap='Blues', edgecolor='grey', figsize=(15, 15));\n",
        "# 'plot' means draw me an image showing the geometry of each feature in my data. \n",
        "# We want to control things like the color of different types of features on our map. \n",
        "# I used the 'Blues' colorscale command (cmap stands for 'colour map') \n",
        "# and asked it to draw the polygons differently based on the type of feature.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVgg9fN1-BQj",
        "colab_type": "text"
      },
      "source": [
        "The colorscale options are: Accent, Accent_r, Blues, Blues_r, BrBG, BrBG_r, BuGn, BuGn_r, BuPu, BuPu_r, CMRmap, CMRmap_r, Dark2, Dark2_r, GnBu, GnBu_r, Greens, Greens_r, Greys, Greys_r, OrRd, OrRd_r, Oranges, Oranges_r, PRGn, PRGn_r, Paired, Paired_r, Pastel1, Pastel1_r, Pastel2, Pastel2_r, PiYG, PiYG_r, PuBu, PuBuGn, PuBuGn_r, PuBu_r, PuOr, PuOr_r, PuRd, PuRd_r, Purples, Purples_r, RdBu, RdBu_r, RdGy, RdGy_r, RdPu, RdPu_r, RdYlBu, RdYlBu_r, RdYlGn, RdYlGn_r, Reds, Reds_r, Set1, Set1_r, Set2, Set2_r, Set3, Set3_r, Spectral, Spectral_r, Wistia, Wistia_r, YlGn, YlGnBu, YlGnBu_r, YlGn_r, YlOrBr, YlOrBr_r, YlOrRd, YlOrRd_r, afmhot, afmhot_r, autumn, autumn_r, binary, binary_r, bone, bone_r, brg, brg_r, bwr, bwr_r, cividis, cividis_r, cool, cool_r, coolwarm, coolwarm_r, copper, copper_r, cubehelix, cubehelix_r, flag, flag_r, gist_earth, gist_earth_r, gist_gray, gist_gray_r, gist_heat, gist_heat_r, gist_ncar, gist_ncar_r, gist_rainbow, gist_rainbow_r, gist_stern, gist_stern_r, gist_yarg, gist_yarg_r, gnuplot, gnuplot2, gnuplot2_r, gnuplot_r, gray, gray_r, hot, hot_r, hsv, hsv_r, inferno, inferno_r, jet, jet_r, magma, magma_r, nipy_spectral, nipy_spectral_r, ocean, ocean_r, pink, pink_r, plasma, plasma_r, prism, prism_r, rainbow, rainbow_r, seismic, seismic_r, spring, spring_r, summer, summer_r, tab10, tab10_r, tab20, tab20_r, tab20b, tab20b_r, tab20c, tab20c_r, terrain, terrain_r, viridis, viridis_r, winter, winter_r\n",
        "\n",
        "Swap out 'Blues' in the cell above for any of these options...\n",
        "\n",
        "<img src=\"https://matplotlib.org/3.1.1/_images/sphx_glr_colormaps_002.png\" width=\"800\"/> </div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asEFZLAQr04v",
        "colab_type": "text"
      },
      "source": [
        "###Now load in the data on the special finds. \n",
        "\n",
        "Like many excavations, not every special find has spatial coordinates associated with it (because in real archaeology life things are found in the sieve, the wheelbarrow, and during washing). \n",
        "\n",
        "This data is not yet spatial, each special find is associated with a stratigraphic unit that does have spatial data, which we loaded in just above. So logically we can merge our non-spatial special finds data with our spatial stratigraphic units data to make all our data spatial.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zikTZlaj-BQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now I'm going to bring in all the basic Gabii special finds data - descriptions, object types, IDs and the contexts from which they come.\n",
        "# We've had a few special finds over the years.\n",
        "sf_su = pd.read_csv(\"https://raw.githubusercontent.com/ropitz/gabii_experiments/master/spf_SU.csv\")\n",
        "sf_su"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JPhVomY-BQn",
        "colab_type": "text"
      },
      "source": [
        "One of our area supervisors, Troy, is super excited about tools related to textile production. They're a great example of how we think about special finds at Gabii. Multiple types of finds are related to textile production. Do we find all types everywhere? Are certain types of tools more concentrated in one type of context or one area than others? Troy has lots of questions about the patterns of places where we find these tools. Do they provide evidence for early textile production? Are they a major factor in the city's early wealth? Do we find the same things in later periods? After all, people under the Republic and Empire wore clothes... Loom Weights, spools, and spindle whorls are the most common weaving tools at Gabii.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCrCdSIQ-BQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's pull all those find types out of the big list. \n",
        "#We're selecting the finds data we want to work with before merging with the spatial data. We could do these operations in reverse if we wanted to.\n",
        "types = ['Loom Weight','Spool','Spindle Whorl']\n",
        "textile_tools = sf_su.loc[sf_su['SF_OBJECT_TYPE'].isin(types)]\n",
        "textile_tools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChQKlGPcs9qM",
        "colab_type": "text"
      },
      "source": [
        "Presence or absences isn't everything. You may want to know how many of a certain type of find is present in a given area."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG9Hbhn0-BQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now let's count up how many of these tools appear in each context (SU).\n",
        "# This command will print out a list of the number of textile tools in each SU next to that SU number.\n",
        "pd.value_counts(textile_tools['SU'].values, sort=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3x4foKL-BQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Then let's combine our polygons representing context shape and location\n",
        "#with the special finds data\n",
        "# We do this with a command called 'merge'\n",
        "\n",
        "gabii_textools = gabii_su_poly.merge(textile_tools, on='SU')\n",
        "\n",
        "# adding .head() to the end of a dataframe name will print out just the first few rows.\n",
        "gabii_textools.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXxiPahi-BQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If we want to see this result as a map, we just add the .plot command to the end of the dataframe's name\n",
        "\n",
        "gabii_textools.plot(column='SF_OBJECT_TYPE', cmap='Accent', figsize=(15, 15), legend=True, alpha=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87-PZM6l-BQz",
        "colab_type": "text"
      },
      "source": [
        "OK, what do you see here? Compare the distribution of each type of textile tool. Do some types seem to be concentrated in certain areas? How might you check? What factors might contribute to this pattern? Do big layer simply aggregate lots of stuff? Do late dumps contain early materials? Why would one type of tool appear where the others don't?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY3cT_mV-BQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can try and see the relationship between layer size and count by sorting\n",
        "#our list of finds by the surface area of each layer.\n",
        "# We use the command 'sort_values'\n",
        "gabii_textools.sort_values(by=['Shape_Area'],ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs3Lvg3O-BQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We have a couple enormous colluvial layers that should probably be excuded.\n",
        "# Outliers will mess with your analysis. Cut out these layers by excluding SUs with a surface area greater than 800.\n",
        "gabii_textools2 = gabii_textools.loc[gabii_textools['Shape_Area']<800]\n",
        "# If we want to see this result as a map, we just add the .plot command to the end again.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXgBTzkX-BQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# That's better. Plot the results to see that you've removed the big colluvial layers.\n",
        "gabii_textools2.plot(column='SF_OBJECT_TYPE', cmap='Accent', figsize=(15, 15), legend=True, alpha=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW8PUkQI-BQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OK, count up how many of each tool type appears in each SU using the 'groupby' command\n",
        "textools_counts = gabii_textools2.groupby('SU')['SF_OBJECT_TYPE'].value_counts().unstack().fillna(0)\n",
        "# Sort the list so that the SUs with the most stuff end up at the top.\n",
        "textools_counts.sort_values(by=['Loom Weight','Spindle Whorl','Spool'], ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZsp42WE-BRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Merge your textile tool counts with your spatial data for the contexts\n",
        "# Because both dataframes have a 'SU' column, you can use this to match up the rows. \n",
        "gabii_textools_counts = gabii_su_poly.merge(textools_counts, on='SU')\n",
        "gabii_textools_counts.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQVlzdgZtU8c",
        "colab_type": "text"
      },
      "source": [
        "Side by side plots of different variables can help you to visualize the differences between the spatial patterns you're exploring."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr_Wmixp-BRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's start by looking at each class of textile tool individually. \n",
        "# Plot the counts of each type of find spatially\n",
        "gabii_textools_counts.plot(column='Loom Weight', cmap='Accent', figsize=(15, 15), legend=True, alpha=0.5)\n",
        "gabii_textools_counts.plot(column='Spindle Whorl', cmap='Accent', figsize=(15, 15), legend=True, alpha=0.5)\n",
        "gabii_textools_counts.plot(column='Spool', cmap='Accent', figsize=(15, 15), legend=True, alpha=0.5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBDAmDtW-BRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base = gabii_textools_counts.plot(column='Loom Weight', cmap='Blues', figsize=(15, 15), legend=True, alpha=0.7)\n",
        "gabii_textools_counts.plot(ax=base, column='Spindle Whorl', cmap='Reds', alpha=0.7)\n",
        "gabii_textools_counts.plot(ax=base, column='Spool', cmap='Greens', alpha=0.7);\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qjbSNcx-BRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# It's hard to see what's happening when we have to scroll. \n",
        "# Let's put the maps side by side.\n",
        "import matplotlib.pyplot as plt\n",
        "fig, axes = plt.subplots(ncols=3,figsize=(15, 5))\n",
        "gabii_textools_counts.plot(column='Loom Weight', cmap='autumn',  ax=axes[0], legend=True).axis('equal')\n",
        "gabii_textools_counts.plot(column='Spindle Whorl', cmap='autumn', ax=axes[1]).axis('equal')\n",
        "gabii_textools_counts.plot(column='Spool', cmap='autumn',ax=axes[2]).axis('equal')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82KrdqwQ-BRM",
        "colab_type": "text"
      },
      "source": [
        "Can you see any patterns here? Do the different types of tools concentrate in the same parts of the site? Why might different types of tools have different distributions? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_WBqeTEtcPh",
        "colab_type": "text"
      },
      "source": [
        "OK, this next big scary cell is because google has broken something in colab after I drafted this exercise. Push run to fix the thing they've broken (hopefully)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l6FaKTG92ZJ",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "#@title\n",
        "!apt-get install -qq curl g++ make\n",
        "#@title\n",
        "!curl -L http://download.osgeo.org/libspatialindex/spatialindex-src-1.8.5.tar.gz | tar xz\n",
        "#@title\n",
        "import os\n",
        "os.chdir('spatialindex-src-1.8.5')\n",
        "#@title\n",
        "!./configure\n",
        "#@title\n",
        "!make\n",
        "#@title\n",
        "!make install\n",
        "#@title\n",
        "!pip install rtree\n",
        "#@title\n",
        "!ldconfig\n",
        "#Working through the example at http://toblerity.org/rtree/examples.html\n",
        "#@title\n",
        "from rtree import index\n",
        "from rtree.index import Rtree\n",
        "#@title\n",
        "p = index.Property()\n",
        "idx = index.Index(properties=p)\n",
        "idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVtbdZPW-BRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I think the distributions of different weaving tools vary.\n",
        "# To investigate further, we are going to need more tools.\n",
        "!pip install pysal\n",
        "import pysal\n",
        "from sklearn import cluster\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qHclmig-BRP",
        "colab_type": "text"
      },
      "source": [
        "We're going to use cluster analysis to try and better understand our patterns. Clustering is a broad set of techniques for finding groups within a data set. When we cluster observations, we want items in the same group to be similar and items in different groups to be dissimilar. Clustering allows us to identify which things are alike on the basis of multiple characteristics. K-means clustering is a simple and frequently applied clustering method for splitting a dataset into a set of k (k being an arbitrary number you get to choose) groups."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkkAU1rK-BRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next step: cluster together contexts where the pattern of the three types of textile tools are similar, \n",
        "# with and without respect to the size of the context.\n",
        "# Make 5 clusters and account for the size of the context and counts of different types of tools. Drop all the other fields.\n",
        "km5 = cluster.KMeans(n_clusters=5)\n",
        "km5cls = km5.fit(gabii_textools_counts.drop(['geometry', 'OBJECTID','DESCRIPTIO','Shape_Length','SU'], axis=1).values)\n",
        "km5cls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqmxImFv-BRW",
        "colab_type": "text"
      },
      "source": [
        "Each cluster produced should contain the SUs that are similar to one another on the basis of the number of each type of textile tool and the size of the surface area of the SU. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZibZbvtQ-BRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Plot the clusters, groups of contexts that have similar textile tool assemblages.\n",
        "# Give a different colour to the SUs that belong to each cluster.\n",
        "\n",
        "f1, ax = plt.subplots(1, figsize=(15,15))\n",
        "\n",
        "gabii_textools_counts.assign(cl=km5cls.labels_)\\\n",
        "   .plot(column='cl', categorical=True, legend=True, \\\n",
        "         linewidth=0.1, cmap='Accent', edgecolor='white', ax=ax)\n",
        "\n",
        "ax.set_axis_off()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cee0MaMR-BRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Do the same, ignoring the size of the context.\n",
        "km5 = cluster.KMeans(n_clusters=5)\n",
        "km5cls2 = km5.fit(gabii_textools_counts.drop(['geometry', 'OBJECTID','DESCRIPTIO','Shape_Length','SU','Shape_Area'], axis=1).values)\n",
        "f2, ax = plt.subplots(1, figsize=(15,15))\n",
        "\n",
        "gabii_textools_counts.assign(cl2=km5cls2.labels_)\\\n",
        "   .plot(column='cl2', categorical=True, legend=True, \\\n",
        "         linewidth=0.1, cmap='Accent', edgecolor='white', ax=ax)\n",
        "\n",
        "ax.set_axis_off()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGObkUxd-BRf",
        "colab_type": "text"
      },
      "source": [
        "The patterns are definitely different. How can we interpret the fact that context size affects the pattern of the distribution of textile tools? Do big units, which perhaps represent dumps or colluvial mashups, have a fundamentally different character than the varied small contexts?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9dmn2j4-BRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at the difference with and without context size taken into accoutn.\n",
        "fig, axes = plt.subplots(ncols=2,figsize=(15, 5))\n",
        "gabii_textools_counts.assign(cl2=km5cls2.labels_)\\\n",
        "   .plot(column='cl2', categorical=True, legend=True, \\\n",
        "         linewidth=0.1, cmap='Accent', edgecolor='white', ax=axes[0]).axis('equal')\n",
        "gabii_textools_counts.assign(cl=km5cls.labels_)\\\n",
        "   .plot(column='cl', categorical=True, legend=True, \\\n",
        "         linewidth=0.1, cmap='Accent', edgecolor='white', ax=axes[1]).axis('equal')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zevk9cjl-BRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# assign the cluster IDs to each context permanently\n",
        "gabiitextools_clas = gabii_textools_counts.assign(cl=km5cls.labels_)\n",
        "gabiitextools_class = gabiitextools_clas.assign(cl2=km5cls2.labels_)\n",
        "gabiitextools_class.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AIxnf2H-BRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now let's look at some individual classes, with and without context size accounted for in the analyses.\n",
        "gabiitextools_class0=gabiitextools_class.loc[gabiitextools_class['cl']==0]\n",
        "gabiitextools_class0noarea=gabiitextools_class.loc[gabiitextools_class['cl2']==0]\n",
        "fig, axes = plt.subplots(ncols=2,figsize=(15, 5))\n",
        "gabiitextools_class0.plot(ax=axes[0], legend=True).axis('equal')\n",
        "gabiitextools_class0noarea.plot(ax=axes[1]).axis('equal')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdCiHX2N-BRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What happens when we change the number of clusters (groups)?\n",
        "km7 = cluster.KMeans(n_clusters=7)\n",
        "km7cls3 = km7.fit(gabii_textools_counts.drop(['geometry', 'OBJECTID','DESCRIPTIO','Shape_Length','SU'], axis=1).values)\n",
        "f3, ax = plt.subplots(1, figsize=(15,15))\n",
        "\n",
        "gabii_textools_counts.assign(cl3=km7cls3.labels_)\\\n",
        "   .plot(column='cl3', categorical=True, legend=True, \\\n",
        "         linewidth=0.1, cmap='Accent', edgecolor='white', ax=ax)\n",
        "\n",
        "ax.set_axis_off()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOd4CQew-BRw",
        "colab_type": "text"
      },
      "source": [
        "That also changes things. Without going into too much detail, finding the ideal number of clusters is a black art. Try playing around with the number of clusters in the notebook, or the size cut-off for inclusion. \n",
        "\n",
        "Cluster analysis is an important statistical technique. While not the main focus of this course, it's worth learning more about it. I encourage you to do some independent reading on this technique."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwtRjnKo-BRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use 7 clusters and plot them\n",
        "km7 = cluster.KMeans(n_clusters=7)\n",
        "km7cls4 = km7.fit(gabii_textools_counts.drop(['geometry', 'OBJECTID','DESCRIPTIO','Shape_Length','SU','Shape_Area'], axis=1).values)\n",
        "f4, ax = plt.subplots(1, figsize=(15,15))\n",
        "\n",
        "gabii_textools_counts.assign(cl4=km7cls4.labels_)\\\n",
        "   .plot(column='cl4', categorical=True, legend=True, \\\n",
        "         linewidth=0.1, cmap='Accent', edgecolor='white', ax=ax)\n",
        "\n",
        "ax.set_axis_off()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfkWHiOZ-BR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's set up to investigate some of the individual clusters\n",
        "gabiitextools_class3=gabiitextools_class.assign(cl3=km7cls3.labels_)\n",
        "gabiitextools_class4=gabiitextools_class3.assign(cl4=km7cls4.labels_)\n",
        "gabiitextools_class4.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8MuyIpe-BR5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up variables to store several classes, with and without context size taken into account.\n",
        "gabiitextools_class0=gabiitextools_class4.loc[gabiitextools_class4['cl']==0]\n",
        "gabiitextools_class0noarea=gabiitextools_class4.loc[gabiitextools_class4['cl2']==0]\n",
        "gabiitextools_k7_class0=gabiitextools_class4.loc[gabiitextools_class4['cl3']==0]\n",
        "gabiitextools_k7_class0noarea=gabiitextools_class4.loc[gabiitextools_class4['cl4']==0]\n",
        "fig, axes = plt.subplots(ncols=2,nrows=2,figsize=(15, 10))\n",
        "gabiitextools_class0.plot(ax=axes[0,0]).axis('equal')\n",
        "axes[0,0].set_title('cl - 5 clusters - area')\n",
        "gabiitextools_class0noarea.plot(ax=axes[0,1]).axis('equal')\n",
        "axes[1,0].set_title('cl2 - 5 clusters - no area')\n",
        "gabiitextools_k7_class0.plot(ax=axes[1,0]).axis('equal')\n",
        "axes[0,1].set_title('cl3 - 7 clusters - area')\n",
        "gabiitextools_k7_class0noarea.plot(ax=axes[1,1]).axis('equal')\n",
        "axes[1,1].set_title('cl - 7 clusters - no area')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoiyIy7o-BR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now try soem different clusters\n",
        "gabiitextools_class3=gabiitextools_class4.loc[gabiitextools_class4['cl']==3]\n",
        "gabiitextools_class3noarea=gabiitextools_class4.loc[gabiitextools_class4['cl2']==3]\n",
        "gabiitextools_k7_class3=gabiitextools_class4.loc[gabiitextools_class4['cl3']==3]\n",
        "gabiitextools_k7_class3noarea=gabiitextools_class4.loc[gabiitextools_class4['cl4']==3]\n",
        "fig, axes = plt.subplots(ncols=2,nrows=2,figsize=(15, 10))\n",
        "gabiitextools_class0.plot(ax=axes[0,0]).axis('equal')\n",
        "axes[0,0].set_title('cl - 5 clusters - area')\n",
        "gabiitextools_class0noarea.plot(ax=axes[0,1]).axis('equal')\n",
        "axes[1,0].set_title('cl2 - 5 clusters - no area')\n",
        "gabiitextools_k7_class0.plot(ax=axes[1,0]).axis('equal')\n",
        "axes[0,1].set_title('cl3 - 7 clusters - area')\n",
        "gabiitextools_k7_class0noarea.plot(ax=axes[1,1]).axis('equal')\n",
        "axes[1,1].set_title('cl - 7 clusters - no area')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kkk4vCFv-7ur",
        "colab": {}
      },
      "source": [
        "# Do 7 clusters as oppossed to 5 result in more correlation?\n",
        "sns.pairplot(gabiitextools_k7_class0.drop(['OBJECTID','DESCRIPTIO','Shape_Length','Shape_Area','SU','geometry','cl','cl2','cl3','cl4'], axis=1), kind=\"reg\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YZe1WBJ_-7M-",
        "colab": {}
      },
      "source": [
        "# Are some clusters more correlated than others?\n",
        "sns.pairplot(gabiitextools_class0.drop(['OBJECTID','DESCRIPTIO','Shape_Length','Shape_Area','SU','geometry','cl','cl2','cl3','cl4'], axis=1), kind=\"reg\")\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiQg_M8G-BSd",
        "colab_type": "text"
      },
      "source": [
        "### That concludes this tutorial.\n",
        "\n",
        "Hopefully you have:\n",
        "* started thinking (and perhaps are a bit confused) about how spatial patterns of different types of finds are created, and how we can interpret them when studying data from an excavation.\n",
        "* learned to combine spatial data and descriptive tables. \n",
        "* learned to use some basic clustering tools, and reinforced your knowledge about how to make charts and maps. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNeDT5daQxgm",
        "colab_type": "text"
      },
      "source": [
        "#LexiCode\n",
        "To re-use the codes - you will need to first load their respective libraries.  So far, you have used ...:\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "> **libraries** | | |\n",
        ">--- |--- | --- | \n",
        ">folium | numpy  | \n",
        ">branca| rtree | \n",
        ">pandas| osmnx| \n",
        ">geopandas| requests | \n",
        ">seaborn | fiona| \n",
        ">matplotlib.pyplot | ipywidgets|\n",
        "> pysal |seaborn |\n",
        "> \n",
        "<br>\n",
        "\n",
        " **plugins**| |\n",
        "--- |--- |\n",
        "HeatMapWithTime\n",
        "HeatMap\n",
        "MeasureControl\n",
        "PrepareUrBasemaps_CreateLayers from [folium.plugins]\n",
        "cluster (from sklearn)\n",
        "\n",
        "<br>\n",
        "\n",
        "your lexicode is non-exhaustive, keep expanding, find your own 'best way' to reuse these code/scripts...\n",
        "\n",
        "<br>\n",
        "\n",
        ">Lexicode_MakingaBasicMap | Lexicode_Webmaps&Distributions |Lexicode_StreetGridOrientations | Lexicode_SpatialPatterns\n",
        ">--- | --- | ---|---|\n",
        ">\t==   () [] | pd.concat() | { } *subselection from list*\n",
        ">.head_csv() | .dtype() | ox.gdf_from_places()|requests.get()\n",
        ">.read_csv() | astype() | ox.plot_shape()\n",
        ">mean()  | fillna()|network_type= ''\n",
        ">folium.Map | def return |ox.add_edge_bearings(ox.get_undirected())\n",
        ">range() | .apply(lambda x:*function*,axis=) |count_and_merge()\n",
        ">len() | pd.merge() |np.arrange()\n",
        ">iloc[]| how= , left_index= ,left_index= |np.histogram()\n",
        ">.value_counts()| gpd.GeoDataFrame()| ax.set_theta_location()\n",
        ">if =:| geometry=gpd.points_from_xy |ax.set_ylim()\n",
        ">elif =: |print() |ax.set_title()\n",
        ">else =:| .isin()|ax.set_yticks()\n",
        ">folium.Marker()| classic.plot()|ax.set_xlabels() & ax.set_yticklabels\n",
        ">folium.Icon()| generateBaseMap()|plt.subplots()\n",
        ">folium.Circle| .groupby(['', ''])|.dropna()\n",
        ">popup= | .reset_index() |polar_plot()\n",
        ">radius= |  max_zoom= |\n",
        ">.values.tolist() |folium.TileLayer()\n",
        "> .add_to()| plugins.DualMap(location= , tiles= , zoom_start= )\n",
        ">  | \n",
        "\n",
        "\n"
      ]
    }
  ]
}